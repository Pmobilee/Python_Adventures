{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains some quick introduction to a simple NLP model, then proceeds to move on to some language exercises."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Kitties\n",
    "\n",
    "These kitties are all trying to study Natural Language Processing, but they're having some trouble. First off, let's install some packages to help us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install scikit-learn\n",
    "!pip install re\n",
    "!pip install nltk\n",
    "!pip install pandas\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def hint(code):\n",
    "    hints = [\n",
    "        \"kitty_dataset = pd.DataFrame(kitty_list)\",\n",
    "        \"use kitty_dataset.columns\"\n",
    "    ]\n",
    "    return hints[code]\n",
    "\n",
    "print(\"Done importing\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words Kitty\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This kitty wants to try out a very simple bag-of-words model, where using Naive-Bayes, you simple determine whether a text is positive or negative (or in our case, is a \"dog\" or \"cat\" sentence) based on the individual words in the sentences. It's simple, yet still efffective. To start off, let's make our own dataset with sentences and their sentiment. \n",
    "\n",
    "**In order to make a later part work, add sentences until 19, and make number 20 to be your test sentence, to test your model later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitty_list = [\n",
    "    [\"I like dogfood\", \"dog\"], #1\n",
    "    [\"Woof!\", \"dog\"], #2\n",
    "    [\"I bark at people\", \"dog\"], #3\n",
    "    [\"I chase my own tail\", \"dog\"], #4\n",
    "    [\"I'm a good boy\", \"dog\"], # 5\n",
    "    [\"I Love dogs\", \"dog\"], # 6\n",
    "    [\"I like wetfood\", \"dog\"], # 7\n",
    "    [\"I miauw at people\", \"cat\"], #8\n",
    "    [\"I purr when stroked\", \"cat\"], # 9\n",
    "    [\"I'm one of the kitties\", \"cat\"], # 10\n",
    "    [\"I hate dogs\", \"cat\"], # 11\n",
    "    [\"I love cats\", \"cat\"], # 12\n",
    "    [\"I'm way smarter'\", \"cat\"], # 13\n",
    "    [\"..\", \"dog\"], # 14\n",
    "    [\"..\", \"cat\"], # 15\n",
    "    [\"..\", \"dog\"], # 16\n",
    "    [\"..\", \"cat\"], # 17\n",
    "    [\"..\", \"dog\"], # 18\n",
    "    [\"..\", \"cat\"], # 19\n",
    "    [\"I'm a cute cat\", \"cat\"], # Test Sentence\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll need to convert this simple nested-list to a pandas dataset. You can google how to (it's actually *that* easy, yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert kitty_list into a pandas kitty_dataset\n",
    "kitty_dataset = .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint\n",
    "hint(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add some columns to the dataset. Think about what the column names could be. What is our data, and what are our labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the dataset some columns\n",
    "kitty_dataset.columns = .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'use kitty_dataset.columns'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint\n",
    "hint(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our dataset now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitty_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the kitty Dataset\n",
    "\n",
    "\n",
    "\n",
    "Awesome! Now, we'll want to clean our dataset so that the eventual model won't learn unnecessary things! There are several ways to do this, but a good strategy is to remove the stop words, as these don't really add anything to classification. We'll also do stemming, which takes the root of all the words, and ignores different versions (like \"ran/running\" -> \"run\"). We'll also remove punctuation and make evrything lowercase.\n",
    "\n",
    "First, let's download the stopwords!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll apply all the transformations to all the sentences we have, and add them to our corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "# Create our normalize function\n",
    "def normalize(text):\n",
    "    text = text.strip(\"!,.\")\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Run it over all instances, and add it to our corpus\n",
    "for i in range(len(kitty_dataset)):\n",
    "    text = kitty_dataset[kitty_dataset.columns[0]][i]\n",
    "    text = normalize(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what our corpus looks like\n",
    "corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus training\n",
    "\n",
    "As you can see, our corpus now contains the raw words, without any special characters, as well as being in lowercase! Next, we'll use the CountVectorizer, to create rows of numbers representing our text, so that the machine can understand us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = kitty_dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this\n",
    "X[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see here, our first entry is just a list of numbers (array to be precise). Every number represents a word that exists ANYWHERE in our dataset. The actual counts (mostly 0/1) are how many times that word is present. It's simple a bag of words.\n",
    "\n",
    "Next, we'll split off our dataset into train and test, where test in this case is our 20th sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fitting naive bayes to the training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, shuffle=False)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X, y)\n",
    "print(\"Done with training!\")\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, now let's see if we managed to successfully predict our last sentence! You can change the last sentence if you want and re-run all the cells to try again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat challenge\n",
    "\n",
    "\n",
    "\n",
    "This exercise is a two-part one. First, you'll make a little function that takes in three values, (chat, nora, true_value). The function must return \"nora\" (NO CAPITAL LETTER) if nora's value is closer, else it will return \"chat\". So for example:\n",
    "\n",
    "```python\n",
    "closer(15, 20, 16) -> \"nora\"\n",
    "closer(5, 99, 10) -> \"chat\"\n",
    "```\n",
    "\n",
    "* Make a function called closer(chat, nora, true_value) that checks which number, that of chat or that of nora is closer to the true value\n",
    "* Return either \"chat\" or \"nora\"\n",
    "* Hint, chat will probably give you a helpful method, this is fine to use\n",
    "\n",
    "Simple right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chat'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def closer(chat, nora, true_value):\n",
    "    return \"chat\" if abs(true_value - chat) < abs(true_value - nora) else \"nora\"\n",
    "\n",
    "closer(1, 5, -19)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's fill in this game function. The function takes as argument *num_wins*, which is the number of wins either chat or nora must have to defeat each other. You must fill in the following:\n",
    "\n",
    "* At part **A**: Ask the chat for a number, store it as **chat**, then you think of a number thats at least 10 digits more or less than chat's number, store it as **nora**\n",
    "* At part **B**: use your closer() function to find out whether chat or nora won, store it as **winner**\n",
    "* At part **C**: Add a \"*\" to the winner's list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def game(num_wins):\n",
    "    chat_wins = []\n",
    "    nora_wins = []\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        # Making sure to generate a number that's difficult to guess\n",
    "        first_num_start = random.randint(1, 15)\n",
    "        first_num_end = random.randint(first_num_start, first_num_start * 5)\n",
    "        first_num = random.randint(first_num_start, first_num_end)\n",
    "        true_value = random.randint(first_num, first_num * 5)\n",
    "\n",
    "        # A !!! get the input values for chat and nora\n",
    "\n",
    "\n",
    "        # B !!! determine the winner\n",
    "\n",
    "\n",
    "        # C !!!  add a \"*\" to the winner list\n",
    "\n",
    "\n",
    "        # The rest is already added\n",
    "        count += 1\n",
    "        print(\"Round\", count)\n",
    "        print(\"Chat Wins:\", \"\".join(chat_wins))\n",
    "        print(\"Nora Wins:\", \"\".join(nora_wins), \"\\n\")\n",
    "\n",
    "        if (len(nora_wins) == num_wins) or (len(chat_wins)  == num_wins):\n",
    "            print(\"Nora Wins!\") if len(nora_wins) > len(chat_wins) else print(\"Chat Wins!\")\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "game(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def game(num_wins):\n",
    "    chat_wins = []\n",
    "    nora_wins = []\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        # Making sure to generate a number that's difficult to guess\n",
    "        first_num_start = random.randint(1, 15)\n",
    "        first_num_end = random.randint(first_num_start, first_num_start * 5)\n",
    "        first_num = random.randint(first_num_start, first_num_end)\n",
    "        true_value = random.randint(first_num, first_num * 5)\n",
    "\n",
    "        # A !!! get the input values for chat and nora\n",
    "        chat = 20\n",
    "        nora = 60\n",
    "\n",
    "\n",
    "        # B !!! determine the winner\n",
    "        winner = closer(chat, nora, true_value)\n",
    "\n",
    "        # C !!!  add a \"*\" to the winner list\n",
    "        if winner == \"nora\":\n",
    "            nora_wins.append(\"*\")\n",
    "        else:\n",
    "            chat_wins.append(\"*\")\n",
    "\n",
    "        # The rest is already added\n",
    "        count += 1\n",
    "        print(\"Round\", count)\n",
    "        print(\"Chat Wins:\", \"\".join(chat_wins))\n",
    "        print(\"Nora Wins:\", \"\".join(nora_wins), \"\\n\")\n",
    "\n",
    "        if (len(nora_wins) == num_wins) or (len(chat_wins)  == num_wins):\n",
    "            print(\"Nora Wins!\") if len(nora_wins) > len(chat_wins) else print(\"Chat Wins!\")\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "game(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kitty De-compression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This question involves decompressing a compressed string. Your input is a compressed string of the format **number[string]** and the decompressed output form should be the string written number times. For example:\n",
    "\n",
    "```python\n",
    "\"3[abc]\"          -> abcabcabc            (3 * abc)\n",
    "\"4[a]c\"           -> aaaac                (4 * a) + (c)\n",
    "\"3[abc]4[ab]c\"    -> abcabcabcababababc   (both combined)\n",
    "```\n",
    "\n",
    "Since this is a junior exercise, the tests won't involve nested versions like **2[3[a]b]**.\n",
    "\n",
    "* Name the function decompress()\n",
    "* Start with a simple example, then move on to the more difficult example if you can\n",
    "* return the output as a string\n",
    "\n",
    "Hint: It might be easier to work with a list version of the compressed string: list(compressed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (208105880.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [159], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    ..\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Work here\n",
    "easy = \"3[abc]\"\n",
    "difficult = \"3[abc]4[ab]c\"\n",
    "\n",
    ".."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test here\n",
    "\n",
    "assert(decompress(\"4[a]c\") == \"aaaac\")\n",
    "assert(decompress(\"3[c]4[a]\") == \"cccaaaa\")\n",
    "assert(decompress(\"2[ac]3[b]1[a]1[d]\") == \"acacbbbad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example solution\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# There are several ways of solving this problem\n",
    "# This method would also solve the actual google interview assignment\n",
    "# With nested \"3[ab2[ac]]c\" versions:\n",
    "def decompress(compressed_string):\n",
    "    # Convert the compressed string to a list\n",
    "    compressed_list = list(compressed_string)\n",
    "\n",
    "    # Loop until no more \"[\" is found in the compressed list\n",
    "    while True:\n",
    "        open_index = []\n",
    "        close_index = []\n",
    "        if \"[\" not in compressed_list:\n",
    "            print(\"Done:\", compressed_list)\n",
    "            return \"\".join(compressed_list)\n",
    "            \n",
    "        # Register where (position) the \"[\" and \"]\" are\n",
    "        for i, char in enumerate(compressed_list):\n",
    "            if char == \"[\":\n",
    "                open_index.append(i)\n",
    "            elif char == \"]\":\n",
    "                close_index.append(i)\n",
    "\n",
    "        # Get the final \"[\" and solve that\n",
    "        final_open_pos = open_index[-1]\n",
    "        count = final_open_pos\n",
    "        while True:\n",
    "            try:\n",
    "                close_pos = close_index[close_index.index(count)]\n",
    "                break\n",
    "            except:\n",
    "                count += 1\n",
    "\n",
    "        # Insert that part into the original compressed string, and do the next loop\n",
    "        temp = int(compressed_list[final_open_pos -1]) * \"\".join(compressed_list[final_open_pos + 1 : close_pos])\n",
    "        list_temp = list(temp)\n",
    "        compressed_list[final_open_pos -1 : close_pos + 1] = list_temp\n",
    "\n",
    "decompress(\"3[ab3[c]]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ebb652c7e935075b0a422c0d1b433309994f32ed4cfc553b7cfde93326650e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
